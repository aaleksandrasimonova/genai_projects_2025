# Отбор на проекты Controllable GenAI (AIRI) и BayesGroup (ВШЭ) 2025-2026
 Этот репозиторий посвящён тестовому заданию для отбора на проекты от Controllable GenAI и BayesGroup. Вам предстоит обучить LoRA-адаптер для базовой диффузионной модели в задаче персонализации объекта или человека. Задание оформляется в виде небольшого пет-проекта, по результатам которого от вас ожидается репозиторий с кодом, чейкпойнт и отчёт. 

Перед началом выполнения задания обязательно зарегистрируйтесь в [форме](https://docs.google.com/forms/d/e/1FAIpQLSf9nS-VcKqAaYn8Ft1bnI_pRwF1puzH6s1Bj5sC-WqrkNg4Zw/viewform?usp=header). В конце регистрационной формы будет ссылка на другую форму, куда сдавать результаты задания.
 
Не пугайтесь объёма описания — оно в первую очередь про аккуратную структуру кода. Адекватные результаты можно получить даже на небольших моделях и в Google Colab (проверено). Вопросы оставляйте в Issues этого репозитория.
  
**Дедлайн** по сдаче задания: **02.11.2025 23:59 МСК**. Дедлайн **жесткий** — работы, присланные после этого времени, не принимаются.

Удачи!

## Оглавление

* [Задание](#задание)

  * [Выбор метода персонализации](#выбор-метода-персонализации)
  * [Ограничения](#ограничения)
* [Формат кода](#формат-кода)

  * [Конфиги](#конфиги)
  * [Логирование](#логирование)
  * [Окружение](#окружение)
* [Данные](#данные)
* [Метрики](#метрики)
* [Отчёт](#отчёт)
* [Оценивание](#оценивание)
 
## Задание
 
Вам предстоит обучить LoRA для диффузионной модели, чтобы она могла хорошо генерировать какой-то конкретный объект. Такая постановка очень близка к тому, чем предстоит заниматься на наших проектах. Есть два варианта:
 
- Обучить LoRA для какого-то конкретного объекта 
- Обучить LoRA под себя (под свои фото)
 
Достаточно сделать один вариант, но если поэкспериментируете с обоими, это будет большим плюсом.

Весь код связанный с заданием должен быть сохранён в **приватном** Github репозитории, ссылку на который нужно будет сдать в форму. **Обязательно** добавьте в Collaborators наш [аккаунт](https://github.com/genaichecker) с разрешением на просмотр файлов, иначе мы не сможем проверить вашу работу.
 
### Выбор метода персонализации
 
Для решения задачи персонализации для начала необходимо зафиксировать базовую диффузионную модель, поверх которой будет обучаться часть с персонализацией. Мы не ограничиваем вас в этом выборе, более того, поощраем, если сможете провести эксперименты с разными базовыми моделями.

Базовый минимум — обучить LoRA, однако, сейчас есть множество других более продвинутых адаптеров. Будет большим плюсом, если вы сможете испробовать разные техники, и сделать по ним свои выводы -- опишите преимущества и недостатки, которые увидите по своим экспериментам. Вот несколько примеров для вдохновения:
- [Textual Inversion](https://arxiv.org/pdf/2208.01618)
- [Dreambooth](https://arxiv.org/abs/2208.12242)
- [Custom Diffusion](https://arxiv.org/pdf/2212.04488)
- [Репозиторий](https://github.com/csyxwei/Awesome-Personalized-Image-Generation) с подборкой свежих работ
 
 
### Ограничения
 
**Важно:** Запрещено использовать предобученные модели, которые из коробки умеют решать задачу персонализации (например [Photomaker](https://github.com/TencentARC/PhotoMaker)). Однако, их можно использовать только как источник идей.
 
Разрешено пользоваться кодом из открытых источников. Например:

- Взять код из открытых репозиториев.
- Использовать peft и подобные библиотеки
- Использовать LLM.
 
Однако, если вы берёте чужой код:
 
1. В отчете нужно указать все заимствования с ссылками на источник, даже если это LLM (см. раздел "Отчет").
2. Необходимо переписать код так, чтобы он соответствовал шаблону из следующего раздела.
 
При невыполнении любого из этих пунктов мы оставляем за собой право аннулировать вашу работу.
 
## Формат кода
 
Код должен быть модульным: отдельные части для данных, архитектуры, обучения, лоссов и т.д. В репозитории есть шаблон структуры кода. Достаточно заполнить недостающие части и добавить нужные модули. Следовать шаблону дословно не обязательно, но сохраняйте ООП-парадигму.


Шаблон ориентирован на обучение адаптеров для диффузионных моделей и основан на [pytorch_project_template](https://github.com/Blinorot/pytorch_project_template).
 
### Конфиги

Мы используем систему конфигов [Hydra](https://hydra.cc/docs/intro). Конфиги лежат в src/configs/ в формате .yaml. Например:
- `src/configs/persongen_train_lora.yaml` — обучение
- `src/configs/persongen_inference_lora.yaml` — инференс



Строки вида `_target_: src.model.sdxl.lora.SDXLLora` означают, что при обращении по ключу, в элементах которого находится этот `_target_` будет инициализирован класс `src.model.sdxl.lora.SDXLLora` с аргументами, расположенными на одном отступе с `_target_` в соответствующем конфиге.

Hydra также поддерживает изменение аргументов через командную строку. К примеру, если нужно изменить `num_images_per_prompt` из валидационных аргументов на `3`, достаточно при запуске скрипта указать:

```bash
python3 train.py validation_args.num_images_per_prompt=3 
```

**Важно**: С финальной моделью нужно сдать два конфига: использумый для обучения, и необходимый для инференса.
 
Обучение должно воспроизводиться командой:
 
```bash
python3 train.py exp.config_path=path/to/train/config.yaml
```
 
Инференс:
 
```bash
python3 inference.py exp.config_path=path/to/inference/config.yaml inferencer.ckpt_dir="path/to/dir/with/ckpt"
```
 
### Логирование
 
Для корректного сравнения результатов экспериментов важно их визуализировать: Сравнивать кривые лоссов, отслеживать метрики и смотреть на получаемые изображения. Для этих целей мы используем сервис [Weights & Biases](https://wandb.ai).

Однако, нам известно, что с недавних пор W&B заблокирован в РФ, поэтому мы предлагаем либо использовать прокси, либо написать свой логгер (по аналогии с `logger/wandb.py`) к любому аналогу (к примеру [ClearML](https://clear.ml)).
 
Минимум, что нужно логировать:
 
- Лоссы.
- Метрики.
- Набор сгенерированных изображений.
 
 
### Окружение
 
Не забудь заполнить файл `requirements.txt` всеми необходимыми библиотеками. Для проверки вашей работы будет создано новое [conda-окружение](https://docs.conda.io/en/latest/) с указанной версией Python (**обязательно укажи ее**), куда установятся все зависимости из `requirements.txt`. Если метод не удастся запустить в этом окружении (отсутствуют библиотеки, несовместимость и т.п.), это повлечет штраф.
 
 
## Метрики
 
Чтобы оценить качество генерируемых моделью изображений, недостаточно нескольких примеров — нужно численно измерить, насколько хорошо она работает на больших объемах данных. Для нашей задачи, классически используется 3 вида метрик: 

- Textlual Similarity -- для измерения того, насколько сгенерированные изображения следуют промпту
- Image Similarity -- для измерения того, насколько сгенерированный объект похож на референс (задача генерации объекта)
- Identity Similarity -- для измерения того, насколько лицо сгенерированного человека похоже на лицо референсного человека(задача генерации человека)

Классы для подсчёта этих метрик мы уже имлементировали, они находятся в директории `metrics`. Выбрать используемые метрики можно с помощью аргумента `inference_metrics` в основном конфиге.

**Hint** Начав ставить эксперименты, вы заметите, что с ходом обучения одни метрики растут, а другие падают. Из-за этого довольно сложно корректно сравнивать разные эксперименты, если приводить сугубо табличные данные, т.к. непонятно, какие чекпойнты для сравнения выбирать. Наша рекоммендация -- строить больше графиков-сравнений, где по осям расположены метрики, разные цвета точек -- разные методы, а разные точки, к примеру, разные чекпойнты (или разные наборы параметров одного метода).

 
## Отчет
 
Одна из самых важных частей задания — **отчет** о проделанной работе. В нем нужно кратко описать все проведенные эксперименты:
 
- **Что проверяет эксперимент?**
- **Какие модификации были внесены?**
- **Какой получился результат?**
 
Обязательно прикладывайте к экспериментам всё что логировалось: лоссы, метрики и получившиеся картинки.

Отчет должен отражать мышление — почему, увидев определенные проблемы, вы предложили именно такие решения. Навык правильной и креативной постановки гипотез — один из самых важных в нашей работе. Можно также добавлять неудавшиеся эксперименты с объяснением, почему так вышло. Отдельно можно описать идеи, которые вам кажутся интересными, но вы не успели их реализовать.
 
 
В отчете также **необходимо** указать:
- Лучшую модель, обосновав, почему вы её выбрали.
- Отдел с заимстованиями кода: что и откуда.

В отчет можно добавить:
- Неудавшиеся эксперименты с объяснением, почему так вышло.
- Идеи, которые вам кажутся интересными, но вы не успели их реализовать.
  
**Важно:** если экспериментировал и с персонализацией объекта, и с персонализацией себя, для каждого типа моделей должен быть **отдельный** отчет. Они будут оцениваться независимо.
 
## Оценивание
 
Оценка будет основана на двух критериях:
 
1. **Качество отчета:**
   - Какие гипотезы были поставлены, и как они проверялись
   - Какие методы были испробованы
   - Оформление отчёта (есть графики, картинки, по которым можно делать выводы и т.п.)
   - Насколько хорошо обучена модель относительно базовой
 
2. **Структура кода:**
   - Разбиение кода на отдельные модули
   - Логирование
   - Работа с конфигами
   - Не обязательно строго следовать шаблону, досаточно придерживаться общих парадигм озвученных выше
 
 
Конкретной системы баллов не даём, но гарантируем: если было приложено достаточно усилий и сделано все, как описано выше -- работа будет оценена по достоинству!
 

Успехов в выполнении задания!
